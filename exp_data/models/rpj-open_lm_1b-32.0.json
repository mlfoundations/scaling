{
    "name": "rpj-open_lm_1b-32.0",
    "dataset_name": "rpj",
    "dataset_uuid": "67db6b77-c7c4-48ae-b431-57254587ed43",
    "hyperparameters": {
        "model": "open_lm_1b",
        "tokens": 921468928000,
        "warmup": 5000,
        "lr": 0.003,
        "wd": 0.033,
        "cd": 3e-05,
        "global_bs": 256,
        "acc": 1,
        "qk_norm": true,
        "z_loss": 0.0001,
        "grad_checkpointing": false,
        "params": 1439795200,
        "params_no_embed": 1336510464,
        "fsdp_flags": [
            "--fsdp",
            "--fsdp-amp",
            "--fsdp-limit-all-gathers"
        ],
        "chinchilla_multiplier": 32.0,
        "seed": 124
    },
    "checkpoint_url": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
    "open_lm_version": "0.0.21",
    "open_lm_args": [
        "--workers",
        "2",
        "--precision",
        "amp_bfloat16",
        "--global-batch-size",
        "256",
        "--log-every-n-steps",
        "20",
        "--grad-clip-norm",
        "1",
        "--lr",
        "0.003",
        "--warmup",
        "5000",
        "--model",
        "open_lm_1b",
        "--wd",
        "0.033",
        "--beta2",
        "0.95",
        "--epochs",
        "5",
        "--resume",
        "latest",
        "--seed",
        "124",
        "--accum-freq",
        "1",
        "--model-norm",
        "gain_only_lp_layer_norm",
        "--delete-previous-checkpoint",
        "--lr-cooldown-end",
        "3e-05",
        "--logs",
        "logs/11578",
        "--train-num-samples",
        "184293785600",
        "--dataset-manifest",
        "s3://tri-ml-datasets/openlm/dcnlp/datasets/rpj/manifest.jsonl",
        "--data-key",
        "json.gz",
        "--name",
        "rpj-open_lm_1b-32.0",
        "--fsdp",
        "--fsdp-amp",
        "--fsdp-limit-all-gathers",
        "--val-data",
        "/home/ubuntu/research/openlm/dcnlp/training/eval_data/open_lm_val/shard_00000000.tar",
        "/home/ubuntu/research/openlm/dcnlp/training/eval_data/c4_val/shard-0000000.tar",
        "--val-frequency",
        "5",
        "--val-data-key",
        "json",
        "txt",
        "--val-tok-ci",
        "--val-seq-ci",
        "--val-max-pop-ci",
        "300000",
        "--qk-norm",
        "--z-loss",
        "0.0001",
        "--remote-sync",
        "s3://tri-ml-datasets/openlm/dcnlp/experiments/1b_32x_rpj-original/"
    ],
    "results": [
        {
            "loss": 1.964944910009702,
            "data_time": 0.3211192488670349,
            "batch_time": 2.0495457500219345,
            "samples_per_second": 165015.5837450794,
            "samples_per_second_per_gpu": 20626.947968134926,
            "loss_sequences_lower_95": 1.9031376107533773,
            "loss_sequences_upper_95": 2.023862336476644,
            "loss_tokens_lower_95": 1.954604393641154,
            "loss_tokens_upper_95": 1.9751269372304279,
            "sequences": 120,
            "tokens": 245760,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/val_tok_mult/openlm/shard_00000000.tar"
            ],
            "model": "open_lm_1b"
        },
        {
            "loss": 2.502053562117363,
            "data_time": 0.005180470722468865,
            "batch_time": 0.5947180263170019,
            "samples_per_second": 441314.8205500726,
            "samples_per_second_per_gpu": 55164.35256875907,
            "loss_sequences_lower_95": 2.4992918988385155,
            "loss_sequences_upper_95": 2.504789996610254,
            "loss_tokens_lower_95": 2.4926991145833335,
            "loss_tokens_upper_95": 2.511524661458333,
            "sequences": 84999,
            "tokens": 174077952,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/c4_val/shard-{0000000..0000010}.tar"
            ],
            "model": "open_lm_1b"
        },
        {
            "loss": 2.509725903784913,
            "data_time": 0.13496361672878265,
            "batch_time": 0.6982705816626549,
            "samples_per_second": 391435.1894382526,
            "samples_per_second_per_gpu": 48929.398679781574,
            "loss_sequences_lower_95": 2.475706957411135,
            "loss_sequences_upper_95": 2.542717374657905,
            "loss_tokens_lower_95": 2.5001837187500002,
            "loss_tokens_upper_95": 2.519444171875,
            "sequences": 491,
            "tokens": 1005568,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/val_tok_mult/paloma_c4_en/00000001.tar"
            ],
            "model": "open_lm_1b"
        },
        {
            "loss": 1.2111714526950097,
            "data_time": 0.016492604464292526,
            "batch_time": 0.5790879666805268,
            "samples_per_second": 435152.91533017193,
            "samples_per_second_per_gpu": 54394.11441627149,
            "loss_sequences_lower_95": 1.1927946752431442,
            "loss_sequences_upper_95": 1.2293929044762435,
            "loss_tokens_lower_95": 1.2029257395833335,
            "loss_tokens_upper_95": 1.2193409661458332,
            "sequences": 4900,
            "tokens": 10035200,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/val_tok_mult/paloma_dolma_100_programing_languages/00000001.tar"
            ],
            "model": "open_lm_1b"
        },
        {
            "loss": 2.726024273934403,
            "data_time": 0.13171962648630142,
            "batch_time": 0.6967286616563797,
            "samples_per_second": 391757.9769989619,
            "samples_per_second_per_gpu": 48969.747124870235,
            "loss_sequences_lower_95": 2.6811039808319834,
            "loss_sequences_upper_95": 2.7716921674526804,
            "loss_tokens_lower_95": 2.715876807291667,
            "loss_tokens_upper_95": 2.7364030364583334,
            "sequences": 492,
            "tokens": 1007616,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/val_tok_mult/paloma_falcon-refinedweb/00000001.tar"
            ],
            "model": "open_lm_1b"
        },
        {
            "loss": 2.7600239569490608,
            "data_time": 0.22262544929981232,
            "batch_time": 0.33804138004779816,
            "samples_per_second": 234547.05587434807,
            "samples_per_second_per_gpu": 29318.381984293508,
            "loss_sequences_lower_95": 2.705270173332908,
            "loss_sequences_upper_95": 2.8152215740897435,
            "loss_tokens_lower_95": 2.742161534049294,
            "loss_tokens_upper_95": 2.777942332354459,
            "sequences": 44,
            "tokens": 90112,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/val_tok_mult/paloma_ptb/00000001.tar"
            ],
            "model": "open_lm_1b"
        },
        {
            "loss": 1.8308175461632865,
            "data_time": 0.1317526251077652,
            "batch_time": 0.531542956829071,
            "samples_per_second": 379243.24701866135,
            "samples_per_second_per_gpu": 47405.40587733267,
            "loss_sequences_lower_95": 1.7599680330593455,
            "loss_sequences_upper_95": 1.8998128596269703,
            "loss_tokens_lower_95": 1.8223029739583332,
            "loss_tokens_upper_95": 1.83970553125,
            "sequences": 343,
            "tokens": 702464,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/val_tok_mult/paloma_redpajama/00000001.tar"
            ],
            "model": "open_lm_1b"
        },
        {
            "loss": 2.3582380935549736,
            "data_time": 0.1684821918606758,
            "batch_time": 0.7236433029174805,
            "samples_per_second": 406248.65142861905,
            "samples_per_second_per_gpu": 50781.08142857738,
            "loss_sequences_lower_95": 2.318412870168686,
            "loss_sequences_upper_95": 2.399759918451309,
            "loss_tokens_lower_95": 2.3482751875,
            "loss_tokens_upper_95": 2.3681900989583333,
            "sequences": 512,
            "tokens": 1048576,
            "checkpoint_path": "rpj-open_lm_1b-32.0/checkpoints/epoch_6.pt",
            "val_data": [
                "training/eval_data/val_tok_mult/de-en/val_de-en_100.tar"
            ],
            "model": "open_lm_1b"
        }
    ],
    "params_url": "rpj-open_lm_1b-32.0/params.txt",
    "uuid": "34c2e23f-c52a-45b1-9090-faf4348156c0",
    "creation_date": "2024_02_04-09_58_11"
}